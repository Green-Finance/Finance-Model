from pydantic import BaseModel
from openai import OpenAI
import json
import os
from datasets import Dataset, load_dataset
import time 
from dotenv import load_dotenv
import pandas as pd 

load_dotenv("../.env")

with open("C:/Users/user/Desktop/Finance-Model/data/cleaned_data.json", 'r', encoding="utf-8") as f:
    dataset = json.load(f)

save_path = "../data/finance_CoT.json"

df = pd.DataFrame(dataset)
dataset = Dataset.from_pandas(df)

# 1. OpenAI client ì´ˆê¸°í™”
client = OpenAI()

# 2. CoT ë°ì´í„°ì…‹ Pydantic ëª¨ë¸ ì •ì˜ (í‚¤ ë³€ê²½)
class CoTDataset(BaseModel):
    instruction: str
    question: str
    complex_cot: str
    answer: str

# 3. í”„ë¡¬í”„íŠ¸ (ìƒˆë¡œìš´ í‚¤ ì´ë¦„ ë°˜ì˜)
prompt = """
Context information is below. You are only aware of this context and nothing else.
---------------------

{context}

---------------------
Given this context, generate exactly **{num_questions}** question(s), answer(s), and chain-of-thought reasoning.

You are a Teacher/Professor in {domain}. 
Your task is to create exactly {num_questions} diverse question(s) for an upcoming quiz/examination.
The question(s) should fully reflect your understanding of the context.
You must provide:
- A question extracted from the context.
- A detailed chain-of-thought (complex_cot) explaining your reasoning process.".
- A final answer in a complete sentence (in Korean)".

IMPORTANT:
- Return the result in JSON format containing the keys `instruction`, `question`, `complex_cot`, and `answer`.
  - `instruction` is fixed: "ë‹¤ìŒ Contextë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œ í•´ê²° ê³¼ì •ì„ ê±°ì³ ì •ë‹µì„ ë„ì¶œí•˜ì„¸ìš”."
  - `question` must contain the question text.
  - `complex_cot` must include the full reasoning process.
  - `answer` must include only the final answer".
- DO NOT use List or Array in JSON. Each QA pair must be a separate JSON object.

## Example Output:
```json
{{
    "instruction": "ë‹¤ìŒ Contextë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ë§¥ê³¼ ìˆ˜ì¹˜ë¥¼ ì°¸ê³ í•˜ì—¬ ë¬¸ì œ í•´ê²° ê³¼ì •ì„ ê±°ì³ ì •ë‹µì„ ë„ì¶œí•˜ì„¸ìš”.",
    "question": "ë°°ì¶œê¶Œì„ ë³´ìœ í•œ ê¸°ì—…ë“¤ì´ ê°€ê²© ìƒìŠ¹ ì‹œ íŒë§¤ë¥¼ ê³ ë ¤í•  ìˆ˜ ìˆë‚˜ìš”?",
    "detailed_explanation": "ê¸°ì—…ì€ ê°ì¶• ë…¸ë ¥ì„ í†µí•´ ì´ˆê³¼ ë°°ì¶œê¶Œì„ ë³´ìœ í•œ ìƒíƒœì´ë©°, ë°°ì¶œê¶Œ ê°€ê²© ìƒìŠ¹ì€ ë³´ìœ  ë°°ì¶œê¶Œì˜ ë‹¨ê°€ë¥¼ ë†’ì—¬ ì¶”ê°€ ìˆ˜ìµ ì°½ì¶œ ê°€ëŠ¥ì„±ì„ ì œê³µí•œë‹¤.",
    "answer": "ì •ë‹µ: ë°°ì¶œê¶Œì„ ë³´ìœ í•œ ê¸°ì—…ë“¤ì€ ê°€ê²©ì´ ìƒìŠ¹í•  ê²½ìš° ì´ˆê³¼ ë°°ì¶œê¶Œì„ íŒë§¤í•˜ì—¬ ìˆ˜ìµì„ ì°½ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë°°ì¶œê¶Œ ê°€ê²©ì´ í†¤ë‹¹ 30,000ì›ì—ì„œ 50,000ì›ìœ¼ë¡œ ìƒìŠ¹í•˜ë©´ 100í†¤ì˜ ì´ˆê³¼ ë°°ì¶œê¶Œì„ ë³´ìœ í•œ ê¸°ì—…ì€ ì•½ 5,000ë§Œ ì›ì˜ ìˆ˜ìµì„ ì˜¬ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
}}
"""



# 4. ë°ì´í„° ìƒì„± í•¨ìˆ˜ ì •ì˜
def generate_cot_dataset(context: str, domain: str = "ê²½ì œ", num_questions: int = 3):
    filled_prompt = prompt.format(context=context, domain=domain, num_questions=num_questions)

    # OpenAI structured output (Pydantic ê¸°ë°˜)
    completion = client.beta.chat.completions.parse(
        model="gpt-4o-2024-08-06",
        messages=[
            {"role": "system", "content": "You are a helpful assistant generating Chain of Thought (CoT) datasets."},
            {"role": "user", "content": filled_prompt}
        ],
        response_format=CoTDataset  # Pydantic ê¸°ë°˜ ì‘ë‹µ íŒŒì‹±
    )

    # ì—¬ëŸ¬ ê°œê°€ ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ choicesë¡œ ë°›ìŒ
    structured_outputs = [choice.message.parsed for choice in completion.choices]
    return structured_outputs

def formatting_prompts_func(examples):
    instructions = examples["input"]  # ì§€ì‹œì‚¬í•­ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    outputs = examples["output"]  # ì¶œë ¥ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    texts = []  # í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    for instruction, output in zip(instructions, outputs):
        # outputì´ ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš° join()ì„ ì‚¬ìš©í•˜ì—¬ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.
        if isinstance(output, list):
            output_text = " ".join(output)
        else:
            output_text = output
        text = instruction + " " + output_text  # ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.
        texts.append(text)
    return {"text": texts}

def save_to_json(data, filename=save_path):
    if not data:
        print("âš ï¸ [WARNING] ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return  # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ

    os.makedirs(os.path.dirname(filename), exist_ok=True)  # âœ… ê²½ë¡œê°€ ì—†ìœ¼ë©´ ìƒì„±

    # âœ… ê¸°ì¡´ íŒŒì¼ ë¡œë“œ
    if os.path.exists(filename):
        with open(filename, "r", encoding="utf-8") as f:
            try:
                existing_data = json.load(f)
            except json.JSONDecodeError:
                print("âš ï¸ JSON íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                existing_data = []
    else:
        existing_data = []

    # âœ… CoTDataset ê°ì²´ë¥¼ `dict`ë¡œ ë³€í™˜ í›„ ì €ì¥
    converted_data = [item.dict() for item in data]  # âœ… ì—¬ê¸°ì„œ `dict()` ë³€í™˜ ì¶”ê°€
    
    existing_data.extend(converted_data)

    # âœ… JSON íŒŒì¼ ì €ì¥
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(existing_data, f, ensure_ascii=False, indent=4)
    print(f"âœ… [INFO] ë°ì´í„° ì €ì¥ ì™„ë£Œ! (ì´ {len(existing_data)}ê°œ)")


# âœ… ì‹¤í–‰ (datasetì„ for ë£¨í”„ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©° ì €ì¥)
if __name__ == "__main__":
    # âœ… ê¸°ì¡´ ë°ì´í„° ê°œìˆ˜ ì„¤ì •
    resume_index = 3082  
    total_examples = len(df)  # âœ… ì›ë³¸ ë°ì´í„° ê°œìˆ˜ í™•ì¸

    print(f"ğŸ”„ [INFO] ê¸°ì¡´ ë°ì´í„° {resume_index}ê°œ ì²˜ë¦¬ë¨. {resume_index + 1}ë²ˆì§¸ë¶€í„° ì‹¤í–‰.")

    # âœ… ë°ì´í„°ì…‹ í¬ë§·íŒ… (ì´ë¯¸ ì²˜ë¦¬ëœ ë¶€ë¶„ ì œì™¸)
    dataset = dataset.map(formatting_prompts_func, batched=True)
    dataset = dataset.select(range(resume_index, total_examples))  # âœ… ì›ë³¸ ê°œìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì„ íƒ

    results = []  # âœ… ì„ì‹œ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    save_every = 5  # âœ… 5ê°œë§ˆë‹¤ ì €ì¥

    try:
        for idx, example in enumerate(dataset, start=resume_index):  # âœ… ê¸°ì¡´ ê°œìˆ˜ë¶€í„° ì‹œì‘
            try:
                context = example["text"]  # í˜„ì¬ ë°ì´í„°ì˜ context ì„ íƒ
                print(f"ğŸ”¹ [{idx+1}/{total_examples}] ë°ì´í„° ì²˜ë¦¬ ì¤‘...")  # âœ… ì´ ë°ì´í„° ê°œìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì§„í–‰ë¥  í‘œì‹œ

                # âœ… CoT ë°ì´í„° ìƒì„±
                cot_data = generate_cot_dataset(context=context,domain="ê²½ì œ")

                if cot_data:
                    results.extend(cot_data)  # âœ… ê²°ê³¼ë¥¼ ì„ì‹œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                else:
                    print("âš ï¸ ë°ì´í„°ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ ì§„í–‰.")

                # âœ… ì¼ì • ê°œìˆ˜ë§ˆë‹¤ ì €ì¥
                if (idx + 1) % save_every == 0 or idx == total_examples - 1:
                    save_to_json(results)
                    print(f"âœ… [INFO] ì €ì¥ ì™„ë£Œ (Index: {idx})")
                    results = []  # âœ… ì„ì‹œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

                time.sleep(1)  # âœ… API ìš”ì²­ ê°„ê²©

            except KeyboardInterrupt:
                print("\nğŸšª [í”„ë¡œê·¸ë¨ ì¢…ë£Œ] í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ ë°œìƒ. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                save_to_json(results)  # âœ… ì¢…ë£Œ ì „ ë°ì´í„° ì €ì¥
                break
            except Exception as e:
                print(f"âš ï¸ [ì˜ˆì™¸ ë°œìƒ] {str(e)}. ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")

    except Exception as e:
        print(f"ğŸš¨ [ì¹˜ëª…ì  ì˜¤ë¥˜] {str(e)}. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        save_to_json(results)  # âœ… í”„ë¡œê·¸ë¨ì´ ë¹„ì •ìƒ ì¢…ë£Œë  ë•Œë„ ë°ì´í„° ì €ì¥
