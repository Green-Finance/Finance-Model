import json
from langgraph.graph import StateGraph, START, END
from langchain.schema import Document
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_community.tools.tavily_search import TavilySearchResults
from typing import List, TypedDict

# vector db
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# PDF 
from langchain_docling import DoclingLoader
from langchain_docling.loader import ExportType
from langchain_text_splitters import MarkdownHeaderTextSplitter

from langchain_ollama import ChatOllama

# search 
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper
from langchain_community.tools import DuckDuckGoSearchResults

# model define 
kanana = ChatOllama(
    model="huihui_ai/kanana-nano-abliterated:2.1b"
    )

seek = ChatOllama(
    model="jinbora/deepseek-r1-Bllossom:8b",
)

# âœ… PDF ë¡œë“œ ë° ë³€í™˜
file_path = "./20250311_industry_897229000.pdf"
loader = DoclingLoader(file_path=file_path, export_type=ExportType.MARKDOWN)
docs = loader.load() 
splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[("#", "Header_1"), ("##", "Header_2"), ("###", "Header_3")])
splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]
texts = [d.page_content for d in splits]

# âœ… ì„ë² ë”© ëª¨ë¸ ë° ë²¡í„° DB ì„¤ì •
model_name = "jhgan/ko-sroberta-multitask"
embedding_model = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={"device": "cpu"}, encode_kwargs={"normalize_embeddings": False})
vdb = FAISS.from_texts(texts, embedding=embedding_model)
retriever = vdb.as_retriever(search_kwargs={"k": 3})

# âœ… DuckDuckGo ê²€ìƒ‰ ì„¤ì •
wrapper = DuckDuckGoSearchAPIWrapper(region="ko-kr", time="d", max_results=5)
search = DuckDuckGoSearchResults(api_wrapper=wrapper, source="news", output_format="list")

# âœ… ìƒíƒœ ì •ì˜
class GraphState(TypedDict):
    question: str  # ì§ˆì˜
    generation: str  # ìƒì„±
    search: str  # ê²€ìƒ‰
    documents: List[Document]  # ë¬¸ì„œ
    steps: List[str]  # ìˆœì„œ
    
# ë¬¸ì„œ ê²€ìƒ‰     
def retrieve(state):
    print("ğŸ” [retrieve] ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘...")
    question = state["question"]
    documents = retriever.invoke(question)
    print(f"ğŸ“„ [retrieve] ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(documents)}")
    return {"documents": documents, "question": question, "steps": state["steps"] + ["retrieve_documents"]}


# âœ… ë¬¸ì„œ í‰ê°€ í”„ë¡¬í”„íŠ¸ (í•œê¸€í™”)
retrieval_grader_prompt = PromptTemplate(
    template="""
    ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ì§€ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    
    - ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆìœ¼ë©´ 1ì ì„ ë¶€ì—¬í•©ë‹ˆë‹¤.
    - ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì—†ìœ¼ë©´ 0ì ì„ ë¶€ì—¬í•©ë‹ˆë‹¤.

    ì§ˆë¬¸: {question}  
    ë¬¸ì„œ ë‚´ìš©: {documents}  

    JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì£¼ì„¸ìš”.  
    {{
      "score": "1" ë˜ëŠ” "0"
    }}
    """,
    input_variables=["question", "documents"],
)

retrieval_grader = retrieval_grader_prompt | kanana | JsonOutputParser()

# ë¬¸ì„œ í‰ê°€ ë…¸ë“œ 
def grade_documents(state):
    print("ğŸ“ [grade_documents] ë¬¸ì„œ í‰ê°€ ì‹œì‘...")
    question = state["question"]
    documents = state["documents"]
    
    filtered_docs = []
    search = "No"

    for d in documents:
        try:
            score = retrieval_grader.invoke({"question": question, "documents": d.page_content})
            print(f"ğŸ“Š [grade_documents] í‰ê°€ ê²°ê³¼: {score}")
            if score["score"] == "1":
                filtered_docs.append(d)
            else:
                search = "Yes"
        except Exception as e:
            print(f"âŒ [grade_documents] ì˜¤ë¥˜ ë°œìƒ: {e}")

    print(f"ğŸ“‘ [grade_documents] ìµœì¢… ìœ íš¨ ë¬¸ì„œ ê°œìˆ˜: {len(filtered_docs)}")
    return {"documents": filtered_docs, "question": question, "search": search, "steps": state["steps"] + ["grade_document_retrieval"]}
# âœ… ì›¹ ê²€ìƒ‰ ë…¸ë“œ (DuckDuckGo ê²€ìƒ‰ ì‚¬ìš©)

def web_search(state):
    print("ğŸŒ [web_search] ì›¹ ê²€ìƒ‰ ì‹œì‘...")
    question = state["question"]
    documents = state.get("documents", [])
    
    try:
        web_results = search.invoke(question)
        documents.extend([Document(page_content=res["content"], metadata={"url": res["url"]}) for res in web_results])
        print(f"ğŸ” [web_search] ì›¹ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜: {len(web_results)}")
    except Exception as e:
        print(f"âŒ [web_search] ì˜¤ë¥˜ ë°œìƒ: {e}")

    return {"documents": documents, "question": question, "steps": state["steps"] + ["web_search"]}



# âœ… ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸
generate_prompt = PromptTemplate(
    template="""
    ë‹¹ì‹ ì€ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆëŠ” ê¸ˆìœµì „ë¬¸ê°€ ì…ë‹ˆë‹¤.
    ì•„ë˜ ì œê³µëœ ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”. 
    
    ë‹¤ìŒ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ë”°ë¼ì£¼ì„¸ìš”:
    1. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.  
    2. ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ í•­ëª©ë³„ë¡œ ì •ë¦¬í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”. 
    3. documentsì— ìˆëŠ” ì •ë³´ë§Œì„ ì‚¬ìš©í•´ì•¼ í•˜ë©°, ì¶”ì¸¡í•˜ê±°ë‚˜ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
    4. ê°€ëŠ¥í•œ ê²½ìš° ì›ë¬¸ì˜ ë¬¸ì¥ì„ ìœ ì§€í•˜ì—¬ ì •ë³´ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.  
    5. ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì´ í¬í•¨ëœ ê²½ìš°, `ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.`ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.  
    6. ì§ˆë¬¸ì— ëŒ€í•œ ëª…í™•í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìœ¼ë©´, 'ì£¼ì–´ì§„ ì •ë³´ë¡œëŠ” ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.'ë¼ê³ ë§Œ ë§í•˜ì„¸ìš”.  
    7. ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. 

    ì§ˆë¬¸: {question}  
    ì°¸ê³  ë¬¸ì„œ: {documents}  
    ë‹µë³€:  
    """,
    input_variables=["question", "documents"],
)

rag_chain = generate_prompt | seek | StrOutputParser()

# âœ… ë‹µë³€ ìƒì„± ë…¸ë“œ
def generate(state):
    print("ğŸ“ [generate] ë‹µë³€ ìƒì„± ì‹œì‘...")
    question = state["question"]
    documents = state["documents"]

    try:
        generation = rag_chain.invoke({"documents": documents, "question": question})
        print(f"âœ… [generate] ìƒì„±ëœ ë‹µë³€: {generation}")
    except Exception as e:
        print(f"âŒ [generate] ì˜¤ë¥˜ ë°œìƒ: {e}")
        generation = "âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"

    return {"documents": documents, "question": question, "generation": generation, "steps": state["steps"] + ["generate_answer"]}

# âœ… ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ ê²°ì •
def decide_to_generate(state):
    return "web_search" if state["search"] == "Yes" else "generate"

# âœ… LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì¶•
workflow = StateGraph(GraphState)

# ğŸ”¹ ë…¸ë“œ ì¶”ê°€
workflow.add_node("retrieve", retrieve)
workflow.add_node("grade_documents", grade_documents)
workflow.add_node("generate", generate)
workflow.add_node("web_search", web_search)

# ğŸ”¹ ë…¸ë“œ ì—°ê²°
workflow.add_edge(START, "retrieve")
workflow.add_edge("retrieve", "grade_documents")
workflow.add_conditional_edges(
    "grade_documents",
    decide_to_generate,
    {
        "web_search": "web_search",
        "generate": "generate",
    },
)
workflow.add_edge("web_search", "generate")
workflow.add_edge("generate", END)


custom_graph = workflow.compile()

# âœ… ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (ë””ë²„ê¹… í¬í•¨)
if __name__ == "__main__":
    query = "ë°˜ë„ì²´ ì‹œì¥ ë™í–¥ ë¶„ì„"
    
    try:
        print("ğŸš€ LangGraph ì‹¤í–‰ ì‹œì‘...")
        result = custom_graph.invoke({"question": query, "steps": []})

        print(f"âœ… LangGraph ì‹¤í–‰ ì„±ê³µ!")
        print(f"ğŸ”¹ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(result['documents'])}")
        print(f"ğŸ“ ìƒì„±ëœ ë‹µë³€: {result['generation']}")
        print(f"ğŸ› ï¸ ìˆ˜í–‰ëœ ë‹¨ê³„: {result['steps']}")

    except Exception as e:
        print(f"âŒ LangGraph ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

